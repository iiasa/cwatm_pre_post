{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Reservoirs\n",
    "\n",
    "*This notebook compares observed and simulated reservoir data at several reservoirs in the Nira river sub-basin of the Upper Bhima basin*\n",
    "\n",
    "\n",
    "Reservoir operations include releasing water to satisfying demands withtin associated command areas as well as releasing water downstream. Releasing water downstream can be to \"deliver\" this water through the river to a downstream \"pick-up\" reservoir, or to not surpass monthly storage maximums. Demand-related releases are determined by matching demand requests up to a maximum. The requests are determined in CWatM as the total of agricultural, domestic, and industrial water demands within the command area of the associated reservoir. The maximum allowable release is related to the historical ratio of daily releases to live storage. Generally, reservoirs are managed optimally by filling as much as possible and consuming the storage. Downstream releases are practiced only when storage surpsses monthly-specific maximums, or to allocate water to another reservoir that will satisfy demands. Reservoir dimensions include maximum live capacity, area, and year of construction. \n",
    "\n",
    "The available data for reservoirs include daily levels, downstream discharge, irrigation use, and inflow. Data is from 1964-2008, although no data is completely available for any reservoir. Organising the data has suggested that there is generally the most confidence with the available storage data. Comparing simualted and historical available storage is interesting as storage is the the end result of downstream releases and water allocations to satisfy water demand. Reservoir levels are translated to available storage using reservoir-specific level-storage curves. Volumes and irrigation use are used to determine a daily rule for for irrigation releaess related to available storage for a general year cycle. Levels are used to determine downstream releases \n",
    " \n",
    "The observed data are kindly offered on behalf of the National Hydrological Project, India."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "## File locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'C:\\\\Data\\\\bhima_Input_mainCWatM\\\\Output/lakeResOutflowDis_daily.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6cf9ac425b5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mVars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mreservoir_nc_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_daily.nc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mSIMULATED_nc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreservoir_nc_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32msrc\\netCDF4\\_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\netCDF4\\_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'C:\\\\Data\\\\bhima_Input_mainCWatM\\\\Output/lakeResOutflowDis_daily.nc'"
     ]
    }
   ],
   "source": [
    "fuse_folder_local = 'C:/GitHub/FUSE'\n",
    "fuse_folder_github = 'C:/GitHub/FUSE'\n",
    "cwatm_folder_local = fuse_folder_local + '/CWATM'\n",
    "#output_folder = 'C:/CWatM_output_Examples/CWatM_output_96_10\n",
    "output_folder = r'C:\\Data\\bhima_Input_mainCWatM\\Output'\n",
    "#output_folder = 'C:/CWatM_output_Examples/CWatM_output_1314_gwaf16'\n",
    "photo_folder = fuse_folder_github + '/Images'\n",
    "measuredData_folder = fuse_folder_local + '/Data_forNotebooks/Reservoir_Historical/Reservoir level_inflow_floodcontrol'\n",
    "\n",
    "#Dam_names = ['Vir','Gunjvane', 'NiraDeoghar', 'Bhatghar']\n",
    "#Inds =  [(164,111), (143,55), (168,66), (159,84)]\n",
    "\n",
    "#Dam_names = ['Vir', 'Bhatghar']\n",
    "#Inds =  [(164,111), (159,84)]\n",
    "\n",
    "\n",
    "\n",
    "#TODO get all dam names?\n",
    "#Dam_names = ['Vir', 'NiraDeoghar', 'Bhatghar', 'Ujjani', 'Chaskaman', 'Dimbhe', 'Bhama Askheda', 'Khadakwasla', 'Yedgaon','Pimpalgaon Joga', 'Temghar','Wadiwale','Andhra']\n",
    "#Inds =  [(164,111), (168,66), (159,84), (170,234), (65, 74), (48,69), (79, 67), (126,72), (38, 102),(22,85), (125, 45),(81,41),(85,57)] \n",
    "#Reservoirs_Sarati = Dam_names\n",
    "\n",
    "Dams_complete = [['Andhra', (85,57)],\n",
    "                 ['Vir', (164,111)],\n",
    "                 ['NiraDeoghar', (168,66)],\n",
    "                 ['Bhatghar', (159,84)],\n",
    "                 ['Ujjani', (170,234)],\n",
    "                 ['Chaskaman',(65, 74)],\n",
    "                 ['Dimbhe', (48,69)],\n",
    "                 ['Bhama Askheda', (79, 67)],\n",
    "                 ['Khadakwasla', (126,72)],\n",
    "                 ['Yedgaon', (38, 102)],\n",
    "                 ['Pimpalgaon Joga', (22,85)],\n",
    "                 ['Temghar', (125, 45)],\n",
    "                 #['Chilhewadi', (18,95)],\n",
    "                 ['Ghod',(98,159)],\n",
    "                 ['Kalmodi',(60,60)],\n",
    "                 #['KasarSai',(105,59)],\n",
    "                 ['Manikdoh',(31,77)],\n",
    "                 ['Mulshi',(116,41)],\n",
    "                 ['Nazare',(143,122)],\n",
    "                 ['Panshet',(134,53)],\n",
    "                 ['Pawana',(98,39)],\n",
    "                 #['SinaKolegaon',(142,267)],\n",
    "                 ['Wadaj', (40,82)],\n",
    "                 ['Wadiwale',(81,41)],\n",
    "                 ['Warasgaon',(133,53)]]\n",
    "\n",
    "Dam_names = [i[0]  for i in Dams_complete]\n",
    "Inds = [i[1] for i in Dams_complete]\n",
    "Reservoirs_Sarati = Dam_names\n",
    "\n",
    "#['SinaNimgaon']\n",
    "#['Tarali']\n",
    "\n",
    "Vars = [['lakeResStorage', 'Lake Level', 'Reservoir Volume', 'Volume (MCM)', 1000000.],\n",
    "        ['lakeResOutflowDis', 'Spilling', 'Reservoir Outflow', 'Outflow (m3/s)', 1.], \n",
    "        ['lakeResInflowDis', 'positive', 'Reservoir Inflow', 'Inflow (m3/s)', 1.],\n",
    "        ['act_bigLakeResAbst', 'Irrigation Use', 'Irrigation Use', 'Volume (MCM)', 1000000.],\n",
    "        ['act_LocalLakeAbstractM3', 'PowerOutlet', 'Basin transfer', 'Volume (MCM)', 1000000.]]\n",
    "\n",
    "        #['act_LocalLakeAbstract', 'PowerOutlet', 'Hydroelectric consumption', 'Outflow (m3/s)', 1/10.]]\n",
    "\n",
    "        #['lakeResStorage_alloc', '', 'Total water in segment', 'Volume (MCM)', 1000000.]] \n",
    "\n",
    "SIMULATED_nc = []\n",
    "\n",
    "for var in Vars:\n",
    "    reservoir_nc_filename = output_folder +'/'+ var[0] + '_daily.nc'\n",
    "    SIMULATED_nc.append(Dataset(reservoir_nc_filename, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Here, we present the locations and names of the reservoirs of interest.\n",
    "\n",
    "Ujjani reservoir is only shown for spatial context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "Dates_simulation = num2date(SIMULATED_nc[0].variables['time'][:], units=SIMULATED_nc[0].variables['time'].units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "The below block of code can be activated to list the locations of the reservoir outlet points ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "Storage = SIMULATED_nc[0].variables['lakeResStorage'][1,:,:]\n",
    "reservoirs = []\n",
    "\n",
    "for i in range(SIMULATED_nc[0].variables['lat'].shape[0]):\n",
    "    for j in range (SIMULATED_nc[0].variables['lon'].shape[0]):\n",
    "        if Storage[i,j] != 0:\n",
    "            \n",
    "            reservoirs.append([Storage[i,j], i, j])\n",
    "            \n",
    "print(reservoirs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dams_all_names = [str(i[0]) for i in reservoirs]\n",
    "Inds_all=[(i[1], i[2]) for i in reservoirs]\n",
    "\n",
    "Dam_names = Dams_all_names\n",
    "Inds =  Inds_all"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dams_operations = [['Vir', (164,111)],['Khadakwasla', (126,72)],['Yedgaon', (38, 102)]]\n",
    "Dam_names = [i[0]  for i in Dams_operations]\n",
    "Inds = [i[1] for i in Dams_operations]\n",
    "Reservoirs_Sarati = Dam_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "DAMS = []\n",
    "\n",
    "for i in range(len(Vars)): \n",
    "    Dams = []\n",
    "    for inds in Inds:\n",
    "        Dams.append(SIMULATED_nc[i].variables[Vars[i][0]][:,inds[0], inds[1]]/Vars[i][4])\n",
    "    DAMS.append(Dams)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "## CWatM Simulations: \n",
    " - Volumes\n",
    " - Discharge\n",
    " - Inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Vars)):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    Dams = DAMS[i]\n",
    "    \n",
    "    for dam_i in range(len(Dams)):\n",
    "        \n",
    "        fig.add_trace(go.Scatter(y=Dams[dam_i],\n",
    "                                 x=Dates_simulation,\n",
    "                        mode='lines',\n",
    "                        name=Dam_names[dam_i]))\n",
    "\n",
    "\n",
    "    fig.update_layout(title = Vars[i][2] +', Simulated',\n",
    "                           xaxis_title='Days',\n",
    "                           yaxis_title= Vars[i][3], template='plotly_dark')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Analysing observed reservoir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xlrd\n",
    "import os   \n",
    "\n",
    "VARS_DATES = []\n",
    "VARS_LEVELS = []\n",
    "VARS_Reservoirs_withLevel = []\n",
    "\n",
    "Reservoirs = os.listdir(measuredData_folder)\n",
    "\n",
    "for var in Vars:\n",
    "    \n",
    "    DATES = []\n",
    "    LEVELS = []\n",
    "    Reservoirs_withLevel = []\n",
    "\n",
    "    for reservoir in Reservoirs:\n",
    "\n",
    "        find_file = [var[1] +'.xlsx' in i for i in os.listdir(measuredData_folder +'/'+ reservoir)]\n",
    "\n",
    "        if True in find_file:\n",
    "\n",
    "            filename = os.listdir(measuredData_folder +'/'+ reservoir)[find_file.index(True)]\n",
    "\n",
    "            book = xlrd.open_workbook(measuredData_folder  +'/'+ reservoir +'/'+ filename)\n",
    "            sheet = book.sheet_by_index(0)\n",
    "            num_rows = sheet.nrows\n",
    "\n",
    "            Dates_fromExcel = [xlrd.xldate_as_tuple(int(sheet.cell(row,0).value), 0) for row in range(2, num_rows)]\n",
    "            Dates = [datetime.datetime(d[0], d[1], d[2]) for d in Dates_fromExcel]\n",
    "\n",
    "            Levels = [sheet.cell(row, 1).value for row in range(2, num_rows)]\n",
    "\n",
    "\n",
    "            DATES.append(Dates)\n",
    "            LEVELS.append(Levels)\n",
    "            Reservoirs_withLevel.append(reservoir)\n",
    "\n",
    "        else:\n",
    "            print('Missing file: '+ var[2] +': '+ reservoir)\n",
    "            DATES.append([])  #26Aug\n",
    "            LEVELS.append([]) #26Aug\n",
    "            Reservoirs_withLevel.append([])  #26Aug\n",
    "                \n",
    "    VARS_DATES.append(DATES)\n",
    "    VARS_LEVELS.append(LEVELS)\n",
    "    VARS_Reservoirs_withLevel.append(Reservoirs_withLevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print(Reservoirs_withLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def level_to_volume(level, reservoir):\n",
    "\n",
    "    if level == '':\n",
    "        volume = ''\n",
    "    else:\n",
    "        if reservoir == 'Veer' or reservoir =='Vir':\n",
    "            # This is total storage: volume = 0.5312*level**2 - 591.26*level + 164526\n",
    "            #volume = np.maximum(0.0145*level**3 - 23.988*level**2 + 13256.1935*level - 2441718.3980, 0)\n",
    "            volume = np.maximum(0.000429759344740*level**4 - 0.9581426788*level**3 + 801.3253017526*level**2 - 297951.0171887190*level + 41557465.3120757000, 0)\n",
    "\n",
    "        elif reservoir == 'Bhatghar':\n",
    "            \n",
    "            # -0,0003x4 + 0,7976x3 - 719,23x2 + 287999x - 4E+07\n",
    "            # Jan 25 commented out volume = 0.5129241275659454*level**2 -602.0396530087479*level + 176662.66875475977\n",
    "            #volume = 0.4836*level**2 -566.54*level + 165930\n",
    "            #volume = np.maximum(0.4836*level**2 -566.54*level + 165923, 0)\n",
    "            volume = np.maximum(-0.000323224291912*level**4 + 0.777689931546950*level**3 - 701.029914519207000*level**2 + 280609.743453543000000*level - 42086156.350895600000000, 0)\n",
    "\n",
    "            # volume = 0.4641*level**2 - 542.84*level + 158709\n",
    "        elif reservoir in ['NiraDeoghar', 'NiraDevdhar']:\n",
    "            #volume = 0.1543*level**2 - 191.37*level + 59331\n",
    "            volume = np.maximum(0.1561*level**2 - 193.77*level + 60109, 0)\n",
    "\n",
    "        elif reservoir == 'Gunjvane':\n",
    "            #volume = y = 0.0988*level**2 - 137.62*level + 47935\n",
    "            volume = np.maximum(0.0987*level**2 - 137.43*level + 47868, 0)\n",
    "            \n",
    "        elif reservoir == 'Ujjani':\n",
    "            volume = np.maximum(12.506*level**2 - 12093.338*level + 2922840.586, 0)\n",
    "            \n",
    "        elif reservoir == 'Bhama Askheda':\n",
    "            volume = np.maximum(0.20555*level**2 - 261.91393*level + 83405.13976, 0)\n",
    "        \n",
    "        elif reservoir == 'Dimbhe':\n",
    "            #volume = np.maximum(-0.003694*level**3 + 7.940284*level**2 - 5676.423596*level + 1349741.967590, 0)\n",
    "            volume = np.maximum(0.1664616*level**2 - 223.5652205*level + 75041.4082410, 0)\n",
    "            # y = 0.1664616x2 - 223.5652205x + 75041.4082410\n",
    "\n",
    "\n",
    "        elif reservoir == 'Chaskaman':\n",
    "            volume = np.maximum(0.35383*level**2 - 442.28380*level + 138211.98361, 0)\n",
    "            \n",
    "        elif reservoir == 'Khadakwasla':\n",
    "            volume = np.maximum(0.6109831*level**2 - 697.8740029*level + 199257.5714402, 0)\n",
    "            \n",
    "        elif reservoir == 'Yedgaon':\n",
    "            volume = np.maximum(2.02303*level**2 - 2569.35622*level + 815810.19337, 0)\n",
    "            \n",
    "        elif reservoir == 'Panshet':\n",
    "            volume = np.maximum(0.167100*level**2 - 198.062297*level + 58673.921562, 0)\n",
    "            \n",
    "        elif reservoir == 'Pimpalgaon Joga':\n",
    "            volume = np.maximum(0.55418*level**2 - 735.63013*level + 243939.10986, 0)\n",
    "            \n",
    "        elif reservoir == 'Temghar':\n",
    "            volume = np.maximum(0.046628*level**2 - 61.605715*level + 20351.132200, 0)\n",
    "            \n",
    "        elif reservoir == 'Wadiwale':\n",
    "            volume = np.maximum(0.055366*level**2 - 66.994903*level + 20250.256295, 0)\n",
    "            \n",
    "        elif reservoir == 'Andhra':\n",
    "            volume = np.maximum(0.00157010*level**3 - 2.68964869*level**2 + 1534.53912421*level - 291578.18317, 0)\n",
    "            \n",
    "        elif reservoir == 'Ghod':\n",
    "            volume = np.maximum(1.32760*level**2 - 1426.48356*level + 383166.52180, 0)\n",
    "        \n",
    "        elif reservoir == 'Kalmodi':\n",
    "            volume = np.maximum(0.000509*level**3 - 0.989796*level**2 + 641.541113*level - 138689.819686, 0)  \n",
    "            \n",
    "        elif reservoir == 'KasarSai':\n",
    "            volume = np.maximum(0.001830*level**3 - 3.330164*level**2 + 2020.120016*level - 408493.726954, 0)\n",
    "            \n",
    "        elif reservoir == 'Manikdoh':\n",
    "            volume = np.maximum(0.001064*level**3 -1.953556*level**2 + 1181.826154*level - 235016.916625, 0)\n",
    "            \n",
    "        elif reservoir == 'Mulshi':\n",
    "            volume = np.maximum(0.513423*level**2 - 581.480574*level + 164361.627297, 0)            \n",
    "            \n",
    "        elif reservoir == 'Nazare':\n",
    "            volume = np.maximum(0.003492*level**3 - 6.890400*level**2 + 4532.207581*level - 993662.492338, 0)\n",
    "\n",
    "        elif reservoir == 'Pawana':\n",
    "            volume = np.maximum(0.505302*level**2 - 597.533194*level + 176646.349060, 0)\n",
    "            \n",
    "        elif reservoir == 'Wadaj':\n",
    "            volume = np.maximum(0.150753*level**2 - 211.842741*level + 74421.419943, 0)\n",
    "        \n",
    "        elif reservoir == 'Warasgaon':\n",
    "            volume = np.maximum(0.218383*level**2 - 261.520212*level + 78295.713907, 0)\n",
    "\n",
    "\n",
    "    \n",
    "    return volume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VARS_MISSING_dates = []\n",
    "VARS_LEVELS_removeNoData = []\n",
    "VARS_DATES_removeNoData = []\n",
    "\n",
    "\n",
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    MISSING_dates = []\n",
    "    LEVELS_removeNoData = []\n",
    "    DATES_removeNoData = []\n",
    "\n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        if VARS_LEVELS[var_i][res_i] != []: #26Aug\n",
    "        \n",
    "            missing_dates = []\n",
    "            Levels_removeNoData = []\n",
    "            Dates_removeNoData = []\n",
    "\n",
    "            Levels = VARS_LEVELS[var_i][res_i]\n",
    "            Dates = VARS_DATES[var_i][res_i]\n",
    "\n",
    "\n",
    "            for i in range(len(Levels)):\n",
    "\n",
    "                if Levels[i] == '' or Levels[i] == 0:\n",
    "                    missing_dates.append(Dates[i])\n",
    "                else:\n",
    "                    Levels_removeNoData.append(Levels[i])\n",
    "                    Dates_removeNoData.append(Dates[i])\n",
    "\n",
    "            percent_missing = int(len(missing_dates)/len(Levels)*100)\n",
    "\n",
    "            print(Vars[var_i][2])\n",
    "            print(VARS_Reservoirs_withLevel[var_i][res_i])\n",
    "            #print(Reservoirs_withLevel[res_i])\n",
    "\n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] +': '+str(percent_missing) + ' % of the values are missing.')\n",
    "            print(Vars[var_i][2] + ' for '+ VARS_Reservoirs_withLevel[var_i][res_i] +': '+str(percent_missing) + ' % of the values are missing.')\n",
    "\n",
    "\n",
    "            MISSING_dates.append(missing_dates)\n",
    "            LEVELS_removeNoData.append(Levels_removeNoData)\n",
    "            DATES_removeNoData.append(Dates_removeNoData) \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            MISSING_dates.append([]) #26Aug\n",
    "            LEVELS_removeNoData.append([]) #26Aug\n",
    "            DATES_removeNoData.append([]) #26Aug\n",
    "            \n",
    "    VARS_MISSING_dates.append(MISSING_dates)\n",
    "    VARS_LEVELS_removeNoData.append(LEVELS_removeNoData)\n",
    "    VARS_DATES_removeNoData.append(DATES_removeNoData)\n",
    "    print('\\n')\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "VARS_VOLUMES_removeNoData = []\n",
    "\n",
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    VOLUMES_removeNoData = []\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(Reservoirs_withLevel)):\n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati:\n",
    "            \n",
    "            Levels = VARS_LEVELS_removeNoData[var_i][res_i]\n",
    "            \n",
    "            if Vars[var_i][1] == 'Lake Level':\n",
    "                Volumes = [level_to_volume(level, Reservoirs_withLevel[res_i]) for level in Levels]\n",
    "                \n",
    "            elif Vars[var_i][1] == 'Irrigation Use':\n",
    "                Volumes = np.array(Levels)*60*60*24/1000000\n",
    "            else:\n",
    "                Volumes = Levels\n",
    "                \n",
    "            Volumes_corrected = [volume if volume=='' or volume<3500 else '' for volume in Volumes]\n",
    "                \n",
    "            VOLUMES_removeNoData.append(Volumes_corrected)\n",
    "            \n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The maximum is ' + str(max(Volumes_corrected)))\n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The minimum is ' + str(min(Volumes_corrected)))\n",
    "\n",
    "        else:\n",
    "            VOLUMES_removeNoData.append([])\n",
    "    \n",
    "    VARS_VOLUMES_removeNoData.append(VOLUMES_removeNoData)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "# Visualisations\n",
    "## Reservoir Volumes, Outflows, and Inflows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true
   },
   "source": [
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati: \n",
    "            \n",
    "            #Dates = VARS_DATES[var_i][res_i]\n",
    "            #Volumes = VARS_VOLUMES[var_i][res_i]\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = VARS_DATES_removeNoData[var_i][res_i],\n",
    "                                     y = VARS_VOLUMES_removeNoData[var_i][res_i], \n",
    "                                     mode='markers',\n",
    "                                     name='Measured'))\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = Dates_simulation, #x,\n",
    "                                     y = DAMS[var_i][Dam_names.index(Reservoirs_withLevel[res_i])],\n",
    "                                     mode='lines',\n",
    "                                     name='Simulated'))\n",
    "\n",
    "            fig.update_layout(title= Vars[var_i][2] +': '+ Reservoirs_withLevel[res_i],\n",
    "                                   xaxis_title='Date (Day)',\n",
    "                                   yaxis_title= Vars[var_i][3])\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "VARS_VOLUMES = []\n",
    "\n",
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    VOLUMES = []\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(Reservoirs_withLevel)):\n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati:\n",
    "            print(Reservoirs_withLevel[res_i])\n",
    "            Levels = VARS_LEVELS[var_i][res_i]\n",
    "            \n",
    "            if Vars[var_i][1] == 'Lake Level':\n",
    "                Volumes = [level_to_volume(level, Reservoirs_withLevel[res_i]) for level in Levels]\n",
    "                \n",
    "            elif Vars[var_i][1] == 'Irrigation Use':\n",
    "                Volumes = np.array(Levels)*60*60*24/1000000\n",
    "            else:\n",
    "                Volumes = Levels\n",
    "                \n",
    "            Volumes_corrected = [volume if volume=='' or volume<3500 else '' for volume in Volumes]\n",
    "                \n",
    "            VOLUMES.append(Volumes_corrected)\n",
    "            \n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The maximum is ' + str(max(Volumes_corrected)))\n",
    "            #print(Vars[var_i][2] + ' for '+ Reservoirs_withLevel[res_i] + ': The minimum is ' + str(min(Volumes_corrected)))\n",
    "\n",
    "        else:\n",
    "            VOLUMES.append([])\n",
    "    \n",
    "    VARS_VOLUMES.append(VOLUMES)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Visualisations\n",
    "## Reservoir Volumes, Outflows, and Inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for var_i in range(len(Vars)):\n",
    "    \n",
    "    Reservoirs_withLevel = VARS_Reservoirs_withLevel[var_i]\n",
    "    \n",
    "    for res_i in range(len(VARS_Reservoirs_withLevel[var_i])):\n",
    "        \n",
    "        if Reservoirs_withLevel[res_i] in Reservoirs_Sarati: \n",
    "            print(Reservoirs_withLevel[res_i])\n",
    "            \n",
    "            Dates = VARS_DATES[var_i][res_i]\n",
    "            Volumes = VARS_VOLUMES[var_i][res_i]\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = VARS_DATES[var_i][res_i],\n",
    "                                     y = VARS_VOLUMES[var_i][res_i], \n",
    "                                     mode='lines',\n",
    "                                     name='Measured'))\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = Dates_simulation, #x,\n",
    "                                     y = DAMS[var_i][Dam_names.index(Reservoirs_withLevel[res_i])],\n",
    "                                     mode='lines',\n",
    "                                     name='Simulated'))\n",
    "\n",
    "            fig.update_layout(title= Vars[var_i][2] +': '+ Reservoirs_withLevel[res_i],\n",
    "                                   xaxis_title='Date (Day)',\n",
    "                                   yaxis_title= Vars[var_i][3], template='plotly_dark')\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
